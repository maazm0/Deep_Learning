{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e42b38",
   "metadata": {},
   "source": [
    "Module 5 â€“ Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "190e0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import  Dropout, Dense, Activation, Flatten,BatchNormalization\n",
    "from keras.layers import  Conv2D,MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd994609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate= 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ed79935",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train),(X_test,Y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c20fd4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train,axis=(0,1,2))\n",
    "std = np.std(X_train,axis=(0,1,2))\n",
    "X_train = (X_train-mean)/(std+1e-7)\n",
    "X_test = (X_test - mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11d1d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "Y_train = np_utils.to_categorical(Y_train,num_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c77117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57c27692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,754\n",
      "Trainable params: 298,858\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay),input_shape = (28,28,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b890427",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range = 15,width_shift_range = 0.1,horizontal_flip = True,)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3afe41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(len(X_train),28,28,1)\n",
    "X_test = X_test.reshape(len(X_test),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5fffeb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "332e19f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mazz Mirza\\anaconda3\\envs\\your-env-name\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "C:\\Users\\Mazz Mirza\\AppData\\Local\\Temp\\ipykernel_15952\\1551155968.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(X_train,Y_train,batch_size=batch_size),steps_per_epoch = X_train.shape[0]//batch_size,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "937/937 [==============================] - 192s 202ms/step - loss: 0.5133 - accuracy: 0.8671 - val_loss: 0.1417 - val_accuracy: 0.9720 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "937/937 [==============================] - 206s 220ms/step - loss: 0.2125 - accuracy: 0.9540 - val_loss: 0.1272 - val_accuracy: 0.9811 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "937/937 [==============================] - 221s 236ms/step - loss: 0.1896 - accuracy: 0.9646 - val_loss: 0.1183 - val_accuracy: 0.9849 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "937/937 [==============================] - 221s 236ms/step - loss: 0.1756 - accuracy: 0.9692 - val_loss: 0.1241 - val_accuracy: 0.9840 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "937/937 [==============================] - 222s 237ms/step - loss: 0.1696 - accuracy: 0.9714 - val_loss: 0.1110 - val_accuracy: 0.9868 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "937/937 [==============================] - 221s 236ms/step - loss: 0.1636 - accuracy: 0.9728 - val_loss: 0.1161 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "937/937 [==============================] - 219s 234ms/step - loss: 0.1552 - accuracy: 0.9754 - val_loss: 0.1498 - val_accuracy: 0.9764 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "937/937 [==============================] - 222s 237ms/step - loss: 0.1507 - accuracy: 0.9758 - val_loss: 0.1253 - val_accuracy: 0.9827 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "937/937 [==============================] - 222s 236ms/step - loss: 0.1481 - accuracy: 0.9763 - val_loss: 0.1114 - val_accuracy: 0.9857 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "937/937 [==============================] - 222s 237ms/step - loss: 0.1470 - accuracy: 0.9765 - val_loss: 0.1166 - val_accuracy: 0.9841 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "937/937 [==============================] - 225s 240ms/step - loss: 0.1395 - accuracy: 0.9776 - val_loss: 0.1160 - val_accuracy: 0.9846 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "937/937 [==============================] - 223s 238ms/step - loss: 0.1393 - accuracy: 0.9773 - val_loss: 0.0979 - val_accuracy: 0.9904 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "937/937 [==============================] - 223s 238ms/step - loss: 0.1352 - accuracy: 0.9783 - val_loss: 0.1032 - val_accuracy: 0.9871 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "937/937 [==============================] - 223s 238ms/step - loss: 0.1323 - accuracy: 0.9791 - val_loss: 0.0998 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "937/937 [==============================] - 223s 238ms/step - loss: 0.1280 - accuracy: 0.9798 - val_loss: 0.1021 - val_accuracy: 0.9864 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "937/937 [==============================] - 225s 240ms/step - loss: 0.1281 - accuracy: 0.9794 - val_loss: 0.0940 - val_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "937/937 [==============================] - 223s 238ms/step - loss: 0.1274 - accuracy: 0.9793 - val_loss: 0.1008 - val_accuracy: 0.9881 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "937/937 [==============================] - 237s 253ms/step - loss: 0.1247 - accuracy: 0.9803 - val_loss: 0.0993 - val_accuracy: 0.9867 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "937/937 [==============================] - 233s 249ms/step - loss: 0.1213 - accuracy: 0.9802 - val_loss: 0.0894 - val_accuracy: 0.9895 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "937/937 [==============================] - 224s 239ms/step - loss: 0.1214 - accuracy: 0.9799 - val_loss: 0.0891 - val_accuracy: 0.9900 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "937/937 [==============================] - 222s 237ms/step - loss: 0.1206 - accuracy: 0.9807 - val_loss: 0.0868 - val_accuracy: 0.9900 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "937/937 [==============================] - 220s 235ms/step - loss: 0.1193 - accuracy: 0.9809 - val_loss: 0.0981 - val_accuracy: 0.9861 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "937/937 [==============================] - 218s 233ms/step - loss: 0.1176 - accuracy: 0.9811 - val_loss: 0.0823 - val_accuracy: 0.9911 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "937/937 [==============================] - 227s 242ms/step - loss: 0.1178 - accuracy: 0.9801 - val_loss: 0.0939 - val_accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "937/937 [==============================] - 218s 233ms/step - loss: 0.1148 - accuracy: 0.9809 - val_loss: 0.0887 - val_accuracy: 0.9880 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "937/937 [==============================] - 215s 230ms/step - loss: 0.1126 - accuracy: 0.9816 - val_loss: 0.0824 - val_accuracy: 0.9916 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "937/937 [==============================] - 215s 229ms/step - loss: 0.1137 - accuracy: 0.9812 - val_loss: 0.0841 - val_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "937/937 [==============================] - 215s 230ms/step - loss: 0.1111 - accuracy: 0.9812 - val_loss: 0.1004 - val_accuracy: 0.9839 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "937/937 [==============================] - 218s 233ms/step - loss: 0.1111 - accuracy: 0.9818 - val_loss: 0.0916 - val_accuracy: 0.9867 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "937/937 [==============================] - 219s 234ms/step - loss: 0.1105 - accuracy: 0.9815 - val_loss: 0.0900 - val_accuracy: 0.9886 - lr: 0.0010\n",
      "79/79 [==============================] - 9s 111ms/step - loss: 0.0900 - accuracy: 0.9886\n",
      "\n",
      "Test result:98.860002 loss:0.090\n"
     ]
    }
   ],
   "source": [
    "opt_rms = keras.optimizers.RMSprop(lr=0.001,decay = 1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer = opt_rms,metrics = ['accuracy'])\n",
    "model.fit_generator(datagen.flow(X_train,Y_train,batch_size=64),steps_per_epoch = X_train.shape[0]//64,\n",
    "                    epochs = 30,verbose = 1,validation_data = (X_test,Y_test),callbacks = [LearningRateScheduler(lr_schedule)])\n",
    "score = model.evaluate(X_test,Y_test,batch_size=128,verbose =1)\n",
    "print('\\nTest result:%3f loss:%.3f'%(score[1]*100,score[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
